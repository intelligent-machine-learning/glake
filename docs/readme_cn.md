# GLake： GPU显存与传输优化库

## 最新消息
文章Link

## 简介
AI大模型训练与推理面临越来越严重的“显存墙”与“传输墙”问题，即显存容量与传输带宽赶不上模型大小增长速度。GLake是一个工作在底层（虚拟与物理显存管理）与系统层（包括多卡、多通道、多任务）的加速库，对显存+传输进行一体优化。GLake使AI模型更充分利用底层硬件资源，训练吞吐提升最高4倍，推理显存节省可达3X，传输加速最高3~12X。使用通常无需代码修改，替换底层lib（如libcuda）即可享受。

### 动机
- **显存瓶颈**：GPU加速卡以高算力、高并发著称。但作为外设，其显存容量（主流训练卡A100最高80GB，主流推理卡A10为24GB）还是明显制约了算力的高效发挥，尤其近年来大模型对显存容量的需求远高于显存硬件的发展。
- **传输瓶颈**：对比GPU算力和显存、传输的硬件指标，不难发现显存墙和传输墙均是短板，且短期难以有效扭转，而基于定制硬件NVLink互联，卡间传输带宽相比PCIe性能大幅领先。此外，显存带宽（HBM、GDDR）在大模型推理上的性能瓶颈。

### 架构
GLake总体架构如下图所示，基于分层设计：
<div align="center">
<img src="figures/glake_arch_cn.png" alt="Editor" width="600">
</div>

- **硬件接口层**：包括加速卡和互联，目前主要是基于NV GPU（支持NVlink、P2P、Unified Addressing、VMM、IPC等），在适配支持国产AI卡，未来考虑支持新型互联（如CXL）。
- **显存池**：提供全局、异构显存池，内置显存碎片优化、多stream-进程复用、安全等特性。
- **核心优化层**：提供增值优化功能，包括全局分配、多路并发、分层、重复数据消重、KV-cache优化等。
- **扩展层**：结合框架和团队自研的VGPU，提供参考集成方案或扩展，例如PyTorch等。
- **应用和生态**：可支持的不同应用场景，目前以AI为主（训练、推理），后续将考虑覆盖图、渲染等。

### 特点
- **高效**：通过显存内部两层管理和全局（多卡、多任务）优化实现显存pooling、sharing和tiering，为训练和推理提供更大的可用显存；通过多通道并发加速传输3~12X
- **易用**：核心功能对模型透明无需修改，包括训练和推理，可插拔到现有引擎上（如PyTorch）
- **开放、易扩展**：将提供可配策略（例如压缩、数据校验、不同级别的安全检查等）
- **安全**：针对显存越界等问题排查困难，将内置显存越界检测机制帮助诊断
   
### 快速结果
1. 典型模型最大可减少碎片率27%，节约显存25G，10B模型训练吞吐最高提升近4倍。
2. 推理显存跨进程、跨模型支持重复显存重复消除，节省显存3X。
3. 加速CPU-GPU数据传输，传输性能提升3X+。
   
## 使用用例
[GMLake tutorial](GMLake/GMLake-tutorial.md)
[Multi-path tutorial](multi_path/README.md)

## 工作原理
- **GMLake** 当没有整块空闲显存满足申请请求时，GMLake会把空闲碎片拼接成一块地址连续的显存返回给用户。

<div align="center">
<img src="figures/gmlake.png" alt="Editor" width="500">
</div>

- **Multi-path** 利用系统内多条CPU-GPU传输路径，同时传输。
<div align="center">
<img src="figures/multi_path_view.png" alt="Editor" width="500">
</div>

- **重复数据消除** 推理场景自动发现内容重复的显存占用，实现细粒度、跨进程自动共享。
<div align="center">
<img src="figures/dedup1.png" alt="Editor" width="500">
</div>

## 路线图
我们将在接下来的时间开源LLM KV-cache优化, cache-prefetch, tiering, 数据消重。


## 交流群
微信，钉钉群
